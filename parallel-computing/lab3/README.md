# Лабораторна робота №3 — MPI: групи процесів, комунікатори, probe, блокувальні та неблокувальні операції

Модуль містить приклади до лабораторної №3: створення груп процесів, формування комунікаторів, використання `probe`, робота з блокувальними та неблокувальними комунікаціями, а також демонстрація виникнення та усунення deadlock’ів.

## Запуск

Усі програми запускаються через Gradle у форматі

```bash
./gradlew lab3:runMpi<ClassName>
```

Приклади:

```bash
./gradlew lab3:runMpiDeadlockProblem
./gradlew lab3:runMpiDeadlockSolution
./gradlew lab3:runMpiTestCreateIntracomm
./gradlew lab3:runMpiTestProbe
./gradlew lab3:runMpiTestWaitFor
```

## DeadlockProblem

Показує тупикову ситуацію, яка виникає, коли два процеси виконують блокувальні `send` у взаємних напрямках. Якщо MPI не може повністю буферизувати дані, обидва процеси зависають, чекаючи один одного.

Цей приклад демонструє типову помилку при симетричному використанні блокувальних комунікацій.

## DeadlockSolution

Виправлений варіант попередньої програми. Один із викликів `send` замінено на неблокувальний `iSend`, після чого викликається `waitFor()`. Завдяки цьому обмін завершується без deadlock’у.

Використання неблокувальних операцій — стандартне рішення при потенційно зустрічних передачах.

## TestCreateIntracomm

Приклад роботи з групами процесів і створення окремих комунікаторів.

* Формуються групи `{0,1,2}` і `{3,4}`.
* Для кожної групи створюється власний `Intracomm`.
* Кожна група виконує свій `bcast`.
* Дані передаються незалежно для різних підгруп.

Приклад демонструє логічне розбиття процесів на підкоманди в межах одного MPI-сеансу.

## TestProbe

Показує, як використовувати `probe` для отримання метаданих про повідомлення до фактичного приймання.

* Процес 0 надсилає масив кожному іншому процесу.
* Інші процеси виконують `probe(0, 1)` і дізнаються:
    * розмір повідомлення (`getCount`)
    * тег
    * джерело
* Потім відбувається звичайний `recv`.

Це корисно в ситуаціях, коли розмір або відправник повідомлення наперед невідомі.

## TestWaitFor

Демонструє використання неблокувальних комунікацій з `Request` у Java MPI, де методи працюють з `Buffer`, а не з масивами.

* Використовується `ByteBuffer.allocateDirect` — лише direct buffer дозволений у MPI.
* Отримується `IntBuffer`.
* Передача здійснюється через `iSend` / `iRecv`.
* Завершення очікується за допомогою `waitFor()`.

Приклад показує коректну роботу з прямими буферами у Java-версії MPI.
